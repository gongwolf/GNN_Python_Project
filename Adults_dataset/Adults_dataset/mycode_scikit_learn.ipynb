{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note about the code below\n",
    "(1) Assign the petal length and petal width of the 150 flower samples to the feature matrix X\n",
    "(2) Assign the corresponding class labels of the flower species to the vector y\n",
    "(3) The Iris flow class names Iris-setosa, Iris-versicolor and Iris-virginica are already stored as integeres 0, 1, 2 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hcao/anaconda/lib/python3.5/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/hcao/anaconda/lib/python3.5/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'target', 'COL_NAMES']\n",
      "mldata.org dataset: mnist-original\n",
      "['label', 'data']\n",
      "[ 0.  0.  0. ...,  9.  9.  9.]\n",
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "print(list(mnist.keys()))\n",
    "print(mnist[\"DESCR\"])\n",
    "print(mnist.COL_NAMES)\n",
    "print(mnist.target)\n",
    "#print(mnist)\n",
    "X_mnist, y_mnist = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X_mnist.shape)\n",
    "print(y_mnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "#iris_data = fetch_mldata('iris')\n",
    "#from sklearn import datasets\n",
    "#import numpy as np \n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4636666666666662\n",
      "-1.3263464400855204e-15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)\n",
    "print(X.mean())\n",
    "print(X_std.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in y [50 50 50]\n",
      "Label counts in y_train [35 35 35]\n",
      "Label counts in y_test [15 15 15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X_std, y, test_size=0.3, random_state=1, stratify=y)\n",
    "print('Label counts in y', np.bincount(y)) \n",
    "print('Label counts in y_train', np.bincount(y_tr))\n",
    "print('Label counts in y_test', np.bincount(y_ts))\n",
    "#print(np.unique(y), \" y length\", y)\n",
    "#print(y_tr)\n",
    "#print(y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      max_iter=40, n_iter=None, n_jobs=1, penalty=None, random_state=1,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=1)\n",
    "ppn.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 7\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=ppn.predict(X_ts) \n",
    "error = (y_ts!=y_pred).sum()\n",
    "print('Misclassified samples: %d' %error)\n",
    "print ('Accuracy: %0.2f' % accuracy_score(y_ts, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "https://machinelearningmastery.com/get-your-hands-dirty-with-scikit-learn-now/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GaussianNB(priors=None)\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.94      0.94      0.94        50\n",
      "          2       0.94      0.94      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "confusion_matrix:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(\"Model\", model)\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "# summarize the fit of the model\n",
    "print(\"report:\\n\" , metrics.classification_report(expected, predicted))\n",
    "print(\"confusion_matrix:\\n\", metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian classifier\n",
    "https://blog.sicara.com/naive-bayes-classifier-sklearn-python-example-tips-42d100429e44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#The following code was not tested. \n",
    "############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Importing dataset\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Convert categorical variable to numeric\n",
    "data[\"Sex_cleaned\"]=np.where(data[\"Sex\"]==\"male\",0,1)\n",
    "data[\"Embarked_cleaned\"]=np.where(data[\"Embarked\"]==\"S\",0,\n",
    "                                  np.where(data[\"Embarked\"]==\"C\",1,\n",
    "                                           np.where(data[\"Embarked\"]==\"Q\",2,3)\n",
    "                                          )\n",
    "                                 )\n",
    "# Cleaning dataset of NaN\n",
    "data=data[[\n",
    "    \"Survived\",\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Embarked_cleaned\"\n",
    "]].dropna(axis=0, how='any')\n",
    "\n",
    "# Split dataset in training and test datasets\n",
    "X_train, X_test = train_test_split(data, test_size=0.5, random_state=int(time.time()))\n",
    "\n",
    "#Instantiate the classifier\n",
    "gnb = GaussianNB()\n",
    "used_features =[\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Embarked_cleaned\"\n",
    "]\n",
    "\n",
    "# Train classifier\n",
    "gnb.fit(\n",
    "    X_train[used_features].values,\n",
    "    X_train[\"Survived\"]\n",
    ")\n",
    "y_pred = gnb.predict(X_test[used_features])\n",
    "\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Survived\"] != y_pred).sum(),\n",
    "          100*(1-(X_test[\"Survived\"] != y_pred).sum()/X_test.shape[0])\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
